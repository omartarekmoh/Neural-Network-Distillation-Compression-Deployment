# ğŸ§  Multi-Stage Model Compression & Deployment

## ğŸš€ Overview
This repository implements a **multi-stage model compression pipeline** for deep learning models. It includes:
1. **Big Model (Teacher)** â€“ A high-performance, large-scale deep learning model.
2. **Distilled Model (Student)** â€“ A smaller, optimized version of the teacher model.
3. **TFLite Model** â€“ A further compressed version of the student model for mobile and edge deployment.

This pipeline demonstrates **knowledge distillation**, **model compression**, and **TensorFlow Lite conversion** for scalable AI applications.

---

## ğŸ“‚ Project Structure

```
ğŸ“¦ Multi-Stage Model Compression
â”œâ”€â”€ models/  # Pre-trained and distilled models
â”‚   â”œâ”€â”€ best_resnet50_model.pth  # Teacher Model (ResNet50)
â”‚   â”œâ”€â”€ best_student.pth  # Distilled Model (ResNet18)
â”‚   â”œâ”€â”€ best_resnet18_model_light.tflite  # TFLite Model
â”œâ”€â”€ server.py  # Flask API for model inference
â”œâ”€â”€ frontend/  # Web interface for testing
â”‚   â”œâ”€â”€ index.html  # Web UI
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ style.css  # CSS Styling
â”‚   â”‚   â”œâ”€â”€ script.js  # JavaScript for UI updates
â”œâ”€â”€ data/  # Data directory (ignored in .gitignore)
â”œâ”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ README.md  # Documentation (this file)
â””â”€â”€ .gitignore  # Git ignore rules
```

---

## ğŸ¯ Features
- âœ… **Knowledge Distillation** â€“ Compresses a large model into a lightweight student model.
- âœ… **TFLite Conversion** â€“ Deploys the model efficiently on mobile and edge devices.
- âœ… **Flask API** â€“ A REST API for serving predictions from all models.
- âœ… **Web Interface** â€“ An interactive UI for testing models.
- âœ… **Class Probability Visualization** â€“ Displays softmax class probabilities using Chart.js.

---

## ğŸ› ï¸ Setup & Installation

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

### **2ï¸âƒ£ Create a Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scriptsctivate      # On Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

---

## ğŸ”¥ Model Training & Knowledge Distillation

The teacher model (ResNet50) is trained on CIFAR-10, and a distilled student model (ResNet18) is obtained using knowledge distillation.

### Train the Teacher Model
```bash
python train_teacher.py --epochs 50 --batch_size 64 --lr 0.001
```

### Train the Student Model with Distillation
```bash
python train_student.py --epochs 50 --batch_size 64 --lr 0.001 --temperature 4.0
```

### Convert Student Model to TFLite
```bash
python convert_tflite.py --model best_student.pth --output best_resnet18_model_light.tflite
```

---

## ğŸŒ Running the Flask API

Start the backend server to serve model predictions via an API.

```bash
python server.py
```

The API will be available at: [http://127.0.0.1:5000](http://127.0.0.1:5000)

### Endpoints:
- **POST** `/predict` â€“ Accepts an image and returns predictions.

---

## ğŸ–¥ï¸ Web UI for Model Testing

A web-based UI allows users to upload images and view predictions and class distributions.

### **1ï¸âƒ£ Start the Web Server**
```bash
cd frontend
python -m http.server 8080
```

### **2ï¸âƒ£ Open in Browser**
Go to: [http://127.0.0.1:8080](http://127.0.0.1:8080)

---

## ğŸ“¡ API Endpoints

### ğŸ“Œ Predict Image Class

#### ğŸ”¹ Request
```http
POST /predict
Content-Type: multipart/form-data
```

| Parameter | Type  | Description          |
|-----------|-------|----------------------|
| file      | image | The input image file |

#### ğŸ”¹ Response
```json
{
    "prediction_finetuned": "dog",
    "finetuned_percentages": [0.1, 0.05, 0.03, 0.02, 0.7, 0.04, 0.02, 0.02, 0.01, 0.01],
    "finetuned_avg_time": 0.0123,
    
    "prediction_distilled": "dog",
    "distilled_percentages": [0.12, 0.03, 0.04, 0.02, 0.65, 0.06, 0.03, 0.02, 0.02, 0.01],
    "distilled_avg_time": 0.0087,

    "prediction_tflite": "dog",
    "tflite_percentages": [0.09, 0.06, 0.02, 0.03, 0.75, 0.02, 0.01, 0.01, 0.005, 0.005],
    "tflite_avg_time": 0.0054
}
```

---

## ğŸ—ï¸ Deployment Options

### **1ï¸âƒ£ Deploy with Docker**
```bash
docker build -t model-compression-api .
docker run -p 5000:5000 model-compression-api
```

### **2ï¸âƒ£ Deploy to Cloud (e.g., AWS, GCP, Heroku)**
- AWS Lambda + API Gateway
- Google Cloud Run
- Heroku with Gunicorn

---

## ğŸ› ï¸ Technologies Used
- **PyTorch** â€“ Model Training & Knowledge Distillation
- **TensorFlow Lite** â€“ Model Conversion for Edge Deployment
- **Flask** â€“ API for Serving Predictions
- **Chart.js** â€“ Data Visualization
- **HTML, CSS, JavaScript** â€“ Web UI

---

## ğŸ¤ Contributing
Contributions are welcome! Follow these steps:

1. Fork the repo
2. Create a feature branch
3. Commit changes
4. Push and open a pull request

---

## âš–ï¸ License
This project is licensed under the **MIT License**.

---

## ğŸ“ Acknowledgments
- **PyTorch & TensorFlow** for model training and deployment tools.
- **Flask & Chart.js** for API and UI components.

---

## ğŸš€ Contact & Links
ğŸ“© **Email:** your.email@example.com  
ğŸ”— **GitHub Repo:** Your Repo Link  
ğŸŒ **Live Demo (if deployed):** Live Link
